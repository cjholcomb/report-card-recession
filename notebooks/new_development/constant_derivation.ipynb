{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1d781868664204c8a955f26536357b7be2b4c5e9ce6e9c004380ad209a06aa79"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/media/cj/HAMMERSPACE/Data Science/dsi/capstones/report-card-recession')\n",
    "from src.produce_datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_all(years, dimension = 'area'):\n",
    "    '''\n",
    "    Combines years of data into a single dataframe, adds qtrid\n",
    "\n",
    "        Parameters: \n",
    "            years (list)\n",
    "            dimension (str): dimension of data to import. Must be 'area' or 'industry'. Default = 'area'\n",
    "\n",
    "        Returns: \n",
    "            df (dataframe)\n",
    "    '''\n",
    "    df = import_one(years[0], dimension)\n",
    "    for year in years[1:]:\n",
    "        df = df.append(import_one(year, dimension))\n",
    "        print(f'{year} complete')\n",
    "    #replaces irregular industry codes and converts to integer\n",
    "    if dimension == 'industry' and year >= 1990:\n",
    "        df['industry_code'] = df['industry_code'].str.replace('31-33','31')\n",
    "        df['industry_code'] = df['industry_code'].str.replace('44-45','44')\n",
    "        df['industry_code'] = df['industry_code'].str.replace('48-49','48').astype('int32')\n",
    "    #adds qtrid column\n",
    "    df = add_qtrid(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1975: 12- Index(['area_fips', 'agglvl_code', 'year', 'qtr', 'area_title', 'agglvl_title',\n",
      "       'qtrly_estabs_count', 'month1_emplvl', 'month2_emplvl', 'month3_emplvl',\n",
      "       'total_qtrly_wages', 'avg_wkly_wage'],\n",
      "      dtype='object')\n",
      "1976: 12- Index(['area_fips', 'agglvl_code', 'year', 'qtr', 'area_title', 'agglvl_title',\n",
      "       'qtrly_estabs_count', 'month1_emplvl', 'month2_emplvl', 'month3_emplvl',\n",
      "       'total_qtrly_wages', 'avg_wkly_wage'],\n",
      "      dtype='object')\n",
      "1977: 12- Index(['area_fips', 'agglvl_code', 'year', 'qtr', 'area_title', 'agglvl_title',\n",
      "       'qtrly_estabs_count', 'month1_emplvl', 'month2_emplvl', 'month3_emplvl',\n",
      "       'total_qtrly_wages', 'avg_wkly_wage'],\n",
      "      dtype='object')\n",
      "1978: 12- Index(['area_fips', 'agglvl_code', 'year', 'qtr', 'area_title', 'agglvl_title',\n",
      "       'qtrly_estabs_count', 'month1_emplvl', 'month2_emplvl', 'month3_emplvl',\n",
      "       'total_qtrly_wages', 'avg_wkly_wage'],\n",
      "      dtype='object')\n",
      "1979: 12- Index(['area_fips', 'agglvl_code', 'year', 'qtr', 'area_title', 'agglvl_title',\n",
      "       'qtrly_estabs_count', 'month1_emplvl', 'month2_emplvl', 'month3_emplvl',\n",
      "       'total_qtrly_wages', 'avg_wkly_wage'],\n",
      "      dtype='object')\n",
      "1980: 12- Index(['area_fips', 'agglvl_code', 'year', 'qtr', 'area_title', 'agglvl_title',\n",
      "       'qtrly_estabs_count', 'month1_emplvl', 'month2_emplvl', 'month3_emplvl',\n",
      "       'total_qtrly_wages', 'avg_wkly_wage'],\n",
      "      dtype='object')\n",
      "1981: 12- Index(['area_fips', 'agglvl_code', 'year', 'qtr', 'area_title', 'agglvl_title',\n",
      "       'qtrly_estabs_count', 'month1_emplvl', 'month2_emplvl', 'month3_emplvl',\n",
      "       'total_qtrly_wages', 'avg_wkly_wage'],\n",
      "      dtype='object')\n",
      "1982: 12- Index(['area_fips', 'agglvl_code', 'year', 'qtr', 'area_title', 'agglvl_title',\n",
      "       'qtrly_estabs_count', 'month1_emplvl', 'month2_emplvl', 'month3_emplvl',\n",
      "       'total_qtrly_wages', 'avg_wkly_wage'],\n",
      "      dtype='object')\n",
      "1983: 12- Index(['area_fips', 'agglvl_code', 'year', 'qtr', 'area_title', 'agglvl_title',\n",
      "       'qtrly_estabs_count', 'month1_emplvl', 'month2_emplvl', 'month3_emplvl',\n",
      "       'total_qtrly_wages', 'avg_wkly_wage'],\n",
      "      dtype='object')\n",
      "1984: 12- Index(['area_fips', 'agglvl_code', 'year', 'qtr', 'area_title', 'agglvl_title',\n",
      "       'qtrly_estabs_count', 'month1_emplvl', 'month2_emplvl', 'month3_emplvl',\n",
      "       'total_qtrly_wages', 'avg_wkly_wage'],\n",
      "      dtype='object')\n",
      "1985: 12- Index(['area_fips', 'agglvl_code', 'year', 'qtr', 'area_title', 'agglvl_title',\n",
      "       'qtrly_estabs_count', 'month1_emplvl', 'month2_emplvl', 'month3_emplvl',\n",
      "       'total_qtrly_wages', 'avg_wkly_wage'],\n",
      "      dtype='object')\n",
      "1986: 12- Index(['area_fips', 'agglvl_code', 'year', 'qtr', 'area_title', 'agglvl_title',\n",
      "       'qtrly_estabs_count', 'month1_emplvl', 'month2_emplvl', 'month3_emplvl',\n",
      "       'total_qtrly_wages', 'avg_wkly_wage'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 47 fields in line 12834, saw 49\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6563d2169249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1975\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{year}: {length}- {columns}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/cj/HAMMERSPACE/Data Science/dsi/capstones/report-card-recession/src/produce_datasets.py\u001b[0m in \u001b[0;36mimport_one\u001b[0;34m(year, dimension)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/source_files/QCEW/'\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mdimension\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_QCEW/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m#all relevant CSVs should be named with only the year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschema_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0;31m#removes redundant entries in industry files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdimension\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'industry'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2145\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2146\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 47 fields in line 12834, saw 49\n"
     ]
    }
   ],
   "source": [
    "for year in range(1975, 2000):\n",
    "    columns = import_one(year).columns\n",
    "    length = len(columns)\n",
    "    print(f'{year}: {length}- {columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = import_all(range(1975,2021))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLES = {}\n",
    "for index, row in df.iterrows():\n",
    "    if row['area_fips'] not in TITLES.keys():\n",
    "        TITLES[row['area_fips']] = row['area_title']\n",
    "TITLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = import_all(range(1990,2021), dimension= 'industry')\n",
    "# for index, row in df.iterrows():\n",
    "#     if row['industry_code'] not in TITLES.keys():\n",
    "#         TITLES[row['industry_code']] = row['industry_title']\n",
    "# for k, v in TITLES.items():\n",
    "#     if v[0:4] == 'NAICS':\n",
    "#         v = v[6:]\n",
    "#         v = ''.join([i for i in v if not i.isdigit()])\n",
    "#         v = v[1:]\n",
    "#         del TITLES[k]\n",
    "#         TITLES[k] = v\n",
    "# for k, v in TITLES.items():\n",
    "#     print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in TITLES.items():\n",
    "#     print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = {}\n",
    "for year in range(1975, 2021):\n",
    "    missing[year] = {}\n",
    "    for fips, name in TITLES.items():\n",
    "        if fips not in df['area_fips']:\n",
    "            missing[year][fips] = name\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing"
   ]
  }
 ]
}